# éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£æä¾›è¯¦ç»†çš„éƒ¨ç½²æŒ‡å¯¼ï¼Œå¸®åŠ©æ‚¨åœ¨ä¸åŒç¯å¢ƒä¸­éƒ¨ç½² Enterprise AI Backendã€‚

## ğŸ“‹ ç›®å½•

- [éƒ¨ç½²å‰å‡†å¤‡](#éƒ¨ç½²å‰å‡†å¤‡)
- [æœ¬åœ°å¼€å‘ç¯å¢ƒ](#æœ¬åœ°å¼€å‘ç¯å¢ƒ)
- [Dockeréƒ¨ç½²](#dockeréƒ¨ç½²)
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](#ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)
- [ç›‘æ§å’Œæ—¥å¿—](#ç›‘æ§å’Œæ—¥å¿—)

## éƒ¨ç½²å‰å‡†å¤‡

### ç³»ç»Ÿè¦æ±‚

- **CPU**: 4æ ¸æˆ–ä»¥ä¸Š
- **å†…å­˜**: 8GBæˆ–ä»¥ä¸Šï¼ˆå»ºè®®16GB+ï¼‰
- **å­˜å‚¨**: 50GBæˆ–ä»¥ä¸Š
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+, CentOS 7+) æˆ– macOS

### ä¾èµ–æœåŠ¡

1. **å‘é‡æ•°æ®åº“** (é€‰æ‹©å…¶ä¸€):
   - Milvus 2.3+ (æ¨è)
   - ChromaDB 0.4+
   - Pinecone
   - Qdrant 1.6+

2. **ç¼“å­˜/è®°å¿†å­˜å‚¨**:
   - Redis 5.0+ (å¿…éœ€)

3. **LLMæœåŠ¡** (é€‰æ‹©å…¶ä¸€):
   - vLLM Server (è‡ªæ‰˜ç®¡)
   - OpenAI API
   - Anthropic API

## æœ¬åœ°å¼€å‘ç¯å¢ƒ

### 1. å…‹éš†ä»£ç 

```bash
git clone https://github.com/your-username/enterprise-ai-backend.git
cd enterprise-ai-backend
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# æˆ–
venv\Scripts\activate  # Windows
```

### 3. å®‰è£…ä¾èµ–

```bash
# ç”Ÿäº§ä¾èµ–
pip install -r requirements.txt

# å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt
```

### 4. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œé…ç½®ä½ çš„æœåŠ¡
```

### 5. å¯åŠ¨æœåŠ¡

```bash
# ä½¿ç”¨uvicornå¯åŠ¨
uvicorn app.main:app --reload --host 0.0.0.0 --port 8080

# æˆ–ä½¿ç”¨Dockerfile
docker build -t enterprise-ai-backend .
docker run -p 8080:8080 --env-file .env enterprise-ai-backend
```

### 6. éªŒè¯éƒ¨ç½²

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8080/health

# æŸ¥çœ‹APIæ–‡æ¡£
open http://localhost:8080/docs
```

## Dockeréƒ¨ç½²

### ä½¿ç”¨Docker Composeï¼ˆæ¨èï¼‰

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f api

# åœæ­¢æœåŠ¡
docker-compose down
```

### å•ç‹¬ä½¿ç”¨Docker

```bash
# æ„å»ºé•œåƒ
docker build -t enterprise-ai-backend:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name enterprise-ai \
  -p 8080:8080 \
  --env-file .env \
  enterprise-ai-backend:latest

# æŸ¥çœ‹æ—¥å¿—
docker logs -f enterprise-ai

# åœæ­¢å®¹å™¨
docker stop enterprise-ai
docker rm enterprise-ai
```

## ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### ç¯å¢ƒé…ç½®æ¸…å•

åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰ï¼Œè¯·ç¡®ä¿å®Œæˆä»¥ä¸‹é…ç½®ï¼š

#### 1. å®‰å…¨é…ç½® âœ…

```bash
# .env
# å¯ç”¨APIå¯†é’¥éªŒè¯
API_KEY_REQUIRED=true
API_KEYS=["sk-prod-xxx", "sk-prod-yyy"]

# CORSé…ç½®ï¼ˆè®¾ç½®ä¸ºä½ çš„å‰ç«¯åŸŸåï¼‰
ALLOWED_ORIGINS=["https://yourdomain.com"]

# å¯ç”¨é€Ÿç‡é™åˆ¶
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# æ—¥å¿—çº§åˆ«
LOG_LEVEL=INFO
```

#### 2. æ•°æ®åº“é…ç½® âœ…

```bash
# Milvusï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
MILVUS_URI=http://milvus-cluster:19530
MILVUS_TOKEN=your-auth-token
MILVUS_COLLECTION=production_knowledge

# Redisï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
REDIS_URL=redis://:password@redis-cluster:6379/0
REDIS_MAX_CONNECTIONS=50
```

#### 3. LLMé…ç½® âœ…

```bash
# é€‰æ‹©LLMæä¾›å•†
LLM_PROVIDER=openai  # æˆ– anthropic, vllm

# OpenAI
OPENAI_API_KEY=sk-xxx
OPENAI_MODEL=gpt-4

# è¶…æ—¶å’Œé‡è¯•
REQUEST_TIMEOUT=60
RETRY_MAX_ATTEMPTS=3
```

#### 4. æ€§èƒ½é…ç½® âœ…

```bash
# ç¼“å­˜
ENABLE_CACHE=true
CACHE_TTL=3600

# æ‰¹é‡æ“ä½œ
BATCH_SIZE=100

# è¿æ¥æ± 
REDIS_MAX_CONNECTIONS=50
```

### ä½¿ç”¨Kuberneteséƒ¨ç½²

åˆ›å»º `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: enterprise-ai-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: enterprise-ai-backend
  template:
    metadata:
      labels:
        app: enterprise-ai-backend
    spec:
      containers:
      - name: api
        image: your-registry/enterprise-ai-backend:latest
        ports:
        - containerPort: 8080
        env:
        - name: MILVUS_URI
          value: "http://milvus:19530"
        - name: REDIS_URL
          value: "redis://redis:6379/0"
        envFrom:
        - secretRef:
            name: ai-backend-secrets
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: enterprise-ai-backend
spec:
  selector:
    app: enterprise-ai-backend
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer
```

åº”ç”¨é…ç½®:

```bash
# åˆ›å»ºsecrets
kubectl create secret generic ai-backend-secrets \
  --from-literal=OPENAI_API_KEY=sk-xxx \
  --from-literal=MILVUS_TOKEN=xxx

# éƒ¨ç½²
kubectl apply -f deployment.yaml

# æŸ¥çœ‹çŠ¶æ€
kubectl get pods
kubectl logs -f deployment/enterprise-ai-backend

# æŸ¥çœ‹æœåŠ¡
kubectl get svc enterprise-ai-backend
```

### ä½¿ç”¨Nginxåå‘ä»£ç†

åˆ›å»º `/etc/nginx/sites-available/enterprise-ai`:

```nginx
upstream backend {
    server 127.0.0.1:8080;
    # å¦‚æœæœ‰å¤šä¸ªå®ä¾‹
    # server 127.0.0.1:8081;
    # server 127.0.0.1:8082;
}

server {
    listen 80;
    server_name api.yourdomain.com;

    # SSLé…ç½®ï¼ˆæ¨èä½¿ç”¨Let's Encryptï¼‰
    # listen 443 ssl http2;
    # ssl_certificate /etc/letsencrypt/live/api.yourdomain.com/fullchain.pem;
    # ssl_certificate_key /etc/letsencrypt/live/api.yourdomain.com/privkey.pem;

    client_max_body_size 50M;

    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # SSEæ”¯æŒ
        proxy_buffering off;
        proxy_cache off;
        proxy_read_timeout 300s;
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        proxy_pass http://backend/health;
        access_log off;
    }
}
```

å¯ç”¨é…ç½®:

```bash
sudo ln -s /etc/nginx/sites-available/enterprise-ai /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
```

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§

1. ç³»ç»Ÿç¯å¢ƒå˜é‡ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
2. `.env` æ–‡ä»¶
3. ä»£ç ä¸­çš„é»˜è®¤å€¼ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰

### å¿…éœ€é…ç½®é¡¹

| é…ç½®é¡¹ | è¯´æ˜ | ç¤ºä¾‹ |
|--------|------|------|
| `LLM_PROVIDER` | LLMæä¾›å•† | `openai`, `anthropic`, `vllm` |
| `LLM_API_KEY` | LLM APIå¯†é’¥ | `sk-xxx` |
| `MILVUS_URI` | Milvusè¿æ¥åœ°å€ | `http://milvus:19530` |
| `REDIS_URL` | Redisè¿æ¥åœ°å€ | `redis://localhost:6379/0` |

### å¯é€‰é…ç½®é¡¹

è¯¦è§ `.env.example` æ–‡ä»¶ã€‚

## æ€§èƒ½è°ƒä¼˜

### 1. åº”ç”¨å±‚ä¼˜åŒ–

```bash
# å¢åŠ workeræ•°é‡ï¼ˆåŸºäºCPUæ ¸å¿ƒæ•°ï¼‰
gunicorn app.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8080 \
  --timeout 120

# æˆ–ä½¿ç”¨uvicorn
uvicorn app.main:app \
  --host 0.0.0.0 \
  --port 8080 \
  --workers 4 \
  --loop uvloop
```

### 2. Redisä¼˜åŒ–

```bash
# å¢åŠ æœ€å¤§è¿æ¥æ•°
REDIS_MAX_CONNECTIONS=100

# å¯ç”¨è¿æ¥æ± 
# ï¼ˆå·²åœ¨ä»£ç ä¸­å®ç°ï¼‰
```

### 3. Milvusä¼˜åŒ–

```bash
# è°ƒæ•´ç´¢å¼•ç±»å‹ï¼ˆæ ¹æ®æ•°æ®è§„æ¨¡ï¼‰
# IVF_FLAT: å°æ•°æ®é›†ï¼ˆ< 100ä¸‡ï¼‰
# IVF_SQ8: ä¸­ç­‰æ•°æ®é›†ï¼ˆ100ä¸‡-1000ä¸‡ï¼‰
# HNSW: å¤§æ•°æ®é›†ï¼ˆ> 1000ä¸‡ï¼‰

# è°ƒæ•´ç›¸ä¼¼åº¦æœç´¢å‚æ•°
SIMILARITY_TOP_K=5  # æ ¹æ®éœ€æ±‚è°ƒæ•´
```

### 4. LLMä¼˜åŒ–

```bash
# è°ƒæ•´è¶…æ—¶æ—¶é—´
REQUEST_TIMEOUT=60

# å¯ç”¨ç¼“å­˜
ENABLE_CACHE=true
CACHE_TTL=3600

# è°ƒæ•´æ‰¹é‡å¤§å°
BATCH_SIZE=100
```

## ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—æ”¶é›†

#### 1. æ–‡ä»¶æ—¥å¿—

```bash
# é…ç½®æ—¥å¿—è¾“å‡º
LOG_LEVEL=INFO

# æ—¥å¿—ä¼šè¾“å‡ºåˆ°stdoutï¼Œå¯ä»¥é‡å®šå‘åˆ°æ–‡ä»¶
uvicorn app.main:app > /var/log/enterprise-ai/app.log 2>&1
```

#### 2. ä½¿ç”¨ELK Stack

```yaml
# docker-compose.yml æ·»åŠ 
filebeat:
  image: docker.elastic.co/beats/filebeat:8.5.0
  volumes:
    - /var/log/enterprise-ai:/var/log/app:ro
    - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
```

### å¥åº·æ£€æŸ¥

```bash
# åŸºæœ¬å¥åº·æ£€æŸ¥
curl http://localhost:8080/health

# è¯¦ç»†å¥åº·æ£€æŸ¥ï¼ˆåŒ…å«ä¾èµ–æœåŠ¡çŠ¶æ€ï¼‰
curl http://localhost:8080/health | jq
```

### æŒ‡æ ‡ç›‘æ§

```bash
# è·å–åº”ç”¨æŒ‡æ ‡
curl http://localhost:8080/metrics

# é›†æˆPrometheusï¼ˆè§ä¸‹ä¸€èŠ‚ï¼‰
```

## æ•…éšœæ’æŸ¥

è¯¦è§ [TROUBLESHOOTING.md](TROUBLESHOOTING.md)

## å®‰å…¨æœ€ä½³å®è·µ

1. âœ… **å¯ç”¨APIå¯†é’¥éªŒè¯**
2. âœ… **ä½¿ç”¨HTTPS**
3. âœ… **é…ç½®CORSç™½åå•**
4. âœ… **å¯ç”¨é€Ÿç‡é™åˆ¶**
5. âœ… **å®šæœŸæ›´æ–°ä¾èµ–**
6. âœ… **ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨æ•æ„Ÿä¿¡æ¯**
7. âœ… **å®šæœŸå¤‡ä»½æ•°æ®**

## å¤‡ä»½å’Œæ¢å¤

### å¤‡ä»½

```bash
# å¤‡ä»½Milvusæ•°æ®
# ï¼ˆä½¿ç”¨Milvuså®˜æ–¹å¤‡ä»½å·¥å…·ï¼‰

# å¤‡ä»½Redisæ•°æ®
redis-cli --rdb /backup/dump.rdb

# å¤‡ä»½é…ç½®
cp .env /backup/env-backup-$(date +%Y%m%d)
```

### æ¢å¤

```bash
# æ¢å¤Redisæ•°æ®
redis-cli --rdb /backup/dump.rdb

# æ¢å¤é…ç½®
cp /backup/env-backup-20240101 .env
```

## æ‰©å±•æ€§

### æ°´å¹³æ‰©å±•

1. éƒ¨ç½²å¤šä¸ªAPIå®ä¾‹
2. ä½¿ç”¨è´Ÿè½½å‡è¡¡å™¨ï¼ˆNginx/HAProxyï¼‰
3. ä½¿ç”¨Redisåˆ†å¸ƒå¼é”ï¼ˆå¦‚æœéœ€è¦ï¼‰
4. ä½¿ç”¨åˆ†å¸ƒå¼é€Ÿç‡é™åˆ¶ï¼ˆRediså®ç°ï¼‰

### å‚ç›´æ‰©å±•

1. å¢åŠ CPUå’Œå†…å­˜
2. ä¼˜åŒ–workeræ•°é‡
3. è°ƒæ•´è¿æ¥æ± å¤§å°

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** æŸ¥çœ‹ [TROUBLESHOOTING.md](TROUBLESHOOTING.md) æˆ–æäº¤Issueã€‚

